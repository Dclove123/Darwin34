{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://cybersecurity-excellence-awards.com/wp-content/uploads/2017/06/366812.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center>Darwin Supervised Classification Model Building </center></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prior to getting started, there are a few things you want to do:\n",
    "1. Set the dataset path.\n",
    "2. Enter your username and password to ensure that you're able to log in successfully\n",
    "\n",
    "Once you're up and running, here are a few things to be mindful of:\n",
    "1. For every run, look up the job status (i.e. requested, failed, running, completed) and wait for job to complete before proceeding. \n",
    "2. If you're not satisfied with your model and think that Darwin can do better by exploring a larger search space, use the resume function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", message=\"numpy.dtype size changed\")\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from IPython.display import Image\n",
    "from time import sleep\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from amb_sdk.sdk import DarwinSdk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Login to Darwin**<br>\n",
    "Enter your registered username and password below to login to Darwin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Login\n",
    "\n",
    "ds = DarwinSdk()\n",
    "\n",
    "ds.set_url('https://amb-demo-api.sparkcognition.com/v1/')\n",
    "\n",
    "status, msg = ds.auth_login_user('ziqichina@outlook.com', 'PXkNucE5VZ')\n",
    "\n",
    "if not status:\n",
    "    print(msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data Path** <br>\n",
    "In the cell below, set the path to your dataset, the default is Darwin's example datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Upload and Clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Read dataset and view a file snippet**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After setting up the dataset path, the next step is to upload the dataset from your local device to the server. <br> In the cell below, you need to specify the dataset_name if you want to use your own data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>state</th>\n",
       "      <th>genus_species</th>\n",
       "      <th>contaminated_ingredient</th>\n",
       "      <th>serotype_or_genotype</th>\n",
       "      <th>etiology_status</th>\n",
       "      <th>location_of_preparation</th>\n",
       "      <th>illnesses</th>\n",
       "      <th>deaths</th>\n",
       "      <th>hospitalizations</th>\n",
       "      <th>food_vehicle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2009</td>\n",
       "      <td>1</td>\n",
       "      <td>Minnesota</td>\n",
       "      <td>Norovirus</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Suspected</td>\n",
       "      <td>Restaurant - Sit-down dining</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2009</td>\n",
       "      <td>1</td>\n",
       "      <td>Minnesota</td>\n",
       "      <td>Norovirus</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Confirmed</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2009</td>\n",
       "      <td>1</td>\n",
       "      <td>Minnesota</td>\n",
       "      <td>Norovirus</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Suspected</td>\n",
       "      <td>Restaurant - Sit-down dining</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2009</td>\n",
       "      <td>1</td>\n",
       "      <td>Minnesota</td>\n",
       "      <td>Norovirus</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Confirmed</td>\n",
       "      <td>Restaurant - \"Fast-food\"(drive up service or p...</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2009</td>\n",
       "      <td>1</td>\n",
       "      <td>Minnesota</td>\n",
       "      <td>Norovirus</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Confirmed</td>\n",
       "      <td>Restaurant - other or unknown type</td>\n",
       "      <td>21</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>cookies</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year  month      state genus_species contaminated_ingredient  \\\n",
       "0  2009      1  Minnesota     Norovirus                     NaN   \n",
       "1  2009      1  Minnesota     Norovirus                     NaN   \n",
       "2  2009      1  Minnesota     Norovirus                     NaN   \n",
       "3  2009      1  Minnesota     Norovirus                     NaN   \n",
       "4  2009      1  Minnesota     Norovirus                     NaN   \n",
       "\n",
       "  serotype_or_genotype etiology_status  \\\n",
       "0                  NaN       Suspected   \n",
       "1                  NaN       Confirmed   \n",
       "2                  NaN       Suspected   \n",
       "3                  NaN       Confirmed   \n",
       "4                  NaN       Confirmed   \n",
       "\n",
       "                             location_of_preparation  illnesses  deaths  \\\n",
       "0                       Restaurant - Sit-down dining          2     0.0   \n",
       "1                                                NaN         16     0.0   \n",
       "2                       Restaurant - Sit-down dining          5     0.0   \n",
       "3  Restaurant - \"Fast-food\"(drive up service or p...          3     0.0   \n",
       "4                 Restaurant - other or unknown type         21     0.0   \n",
       "\n",
       "   hospitalizations food_vehicle  \n",
       "0               0.0          NaN  \n",
       "1               0.0          NaN  \n",
       "2               0.0          NaN  \n",
       "3               0.0          NaN  \n",
       "4               0.0      cookies  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dataset_name = 'cancer_train.csv'\n",
    "#df = pd.read_csv(os.path.join(path, dataset_name))\n",
    "df = pd.read_csv('outbreak.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Upload dataset to Darwin**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400: BAD REQUEST - {\"message\": \"Dataset already exists\"}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Upload dataset\n",
    "status, dataset = ds.upload_dataset('outbreak.csv','outbreak')\n",
    "if not status:\n",
    "    print(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Clean dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True,\n",
       " {'job_name': '2b429de3a75f48e3b9b2ec07af2bab73',\n",
       "  'artifact_name': 'e6c48bc53a0b42508a337dcd11d86c44'})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.analyze_data('outbreak')\n",
    "#should we exclude labels?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True,                    col_name num_uniques                mean  \\\n",
       " 0                      year          18  2005.5623725090225   \n",
       " 1                     month          12   6.433443171714002   \n",
       " 2                     state          55                None   \n",
       " 3             genus_species         213                None   \n",
       " 4   contaminated_ingredient         365                None   \n",
       " 5      serotype_or_genotype         265                None   \n",
       " 6           etiology_status          22                None   \n",
       " 7   location_of_preparation         220                None   \n",
       " 8                 illnesses         291                None   \n",
       " 9                    deaths          14                None   \n",
       " 10         hospitalizations          59  0.9505615076803924   \n",
       " 11             food_vehicle        3088                None   \n",
       " \n",
       "                stddev   min   max     col_type   missing num_with_str_outlier  \\\n",
       " 0   5.158403941746534  1998  2015  IntegerType  0.000000                False   \n",
       " 1   3.432970119168651     1    12  IntegerType  0.000000                False   \n",
       " 2                None  None  None   StringType  0.000000                False   \n",
       " 3                None  None  None   StringType  0.346200                False   \n",
       " 4                None  None  None   StringType  0.901302                False   \n",
       " 5                None  None  None   StringType  0.795648                False   \n",
       " 6                None  None  None   StringType  0.346200                False   \n",
       " 7                None  None  None   StringType  0.059365                False   \n",
       " 8                None  None  None   StringType  0.000000                 True   \n",
       " 9                None  None  None   StringType  0.188347                False   \n",
       " 10  5.322335291989943     0   308  IntegerType  0.189602                False   \n",
       " 11               None  None  None   StringType  0.468801                 True   \n",
       " \n",
       "    scalable is_cat notes   drop target  \\\n",
       " 0      True  False        False  False   \n",
       " 1     False   True        False  False   \n",
       " 2     False   True         True  False   \n",
       " 3     False   True         True  False   \n",
       " 4     False   True         True  False   \n",
       " 5     False   True         True  False   \n",
       " 6     False   True        False  False   \n",
       " 7     False   True         True  False   \n",
       " 8     False   True         True  False   \n",
       " 9     False   True        False  False   \n",
       " 10     True  False        False  False   \n",
       " 11    False   True         True  False   \n",
       " \n",
       "                                               uniques  \n",
       " 0   ['1998', '1999', '2000', '2001', '2002', '2003...  \n",
       " 1   ['1', '10', '11', '12', '2', '3', '4', '5', '6...  \n",
       " 2                                                None  \n",
       " 3                                                None  \n",
       " 4                                                None  \n",
       " 5                                                None  \n",
       " 6   ['Confirmed', 'Confirmed; Confirmed', 'Confirm...  \n",
       " 7                                                None  \n",
       " 8                                                None  \n",
       " 9   [' other temp or mobile services\"', ' other te...  \n",
       " 10                                               None  \n",
       " 11                                               None  )"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.download_artifact('e6c48bc53a0b42508a337dcd11d86c44')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'status': 'Requested', 'starttime': '2019-04-17T17:35:42.758501', 'endtime': None, 'percent_complete': 0, 'job_type': 'CleanDataTiny', 'loss': None, 'generations': None, 'dataset_names': ['outbreak'], 'artifact_names': ['1004902ca53d4c5b9878b50c525d9f01'], 'model_name': None, 'job_error': None}\n",
      "{'status': 'Complete', 'starttime': '2019-04-17T17:35:42.758501', 'endtime': '2019-04-17T17:35:48.263794', 'percent_complete': 100, 'job_type': 'CleanDataTiny', 'loss': None, 'generations': None, 'dataset_names': ['outbreak'], 'artifact_names': ['1004902ca53d4c5b9878b50c525d9f01'], 'model_name': None, 'job_error': ''}\n"
     ]
    }
   ],
   "source": [
    "# clean dataset\n",
    "\n",
    "# how we feature engineering.....\n",
    "features=['genus_species','location_of_preparation','food_vehicle']\n",
    "\n",
    "\n",
    "    \n",
    "target = 'illnesses'\n",
    "status, job_id = ds.clean_data('outbreak', target = target)\n",
    "\n",
    "if status:\n",
    "    ds.wait_for_job(job_id['job_name'])\n",
    "else:\n",
    "    print(job_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True,\n",
       " {'filename': 'C:\\\\data\\\\outbreak-part0-v4yetsr2.csv',\n",
       "  'part': 0,\n",
       "  'note': 'part 0 of 0'})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.download_dataset('outbreak',artifact_path='C:/data/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create and Train Model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now build a model that will learn the class labels in the target column.<br> In the default cancer dataset, the target column is \"Diagnosis\". <br> You will have to specify your own target name for your custom dataset. <br> You can also increase max_train_time for longer training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'status': 'Requested', 'starttime': '2019-04-17T17:37:14.580578', 'endtime': None, 'percent_complete': 0, 'job_type': 'TrainModel', 'loss': None, 'generations': 0, 'dataset_names': ['outbreak'], 'artifact_names': None, 'model_name': 'illnesses_model1', 'job_error': None}\n",
      "{'status': 'Running', 'starttime': '2019-04-17T17:37:14.580578', 'endtime': None, 'percent_complete': 7, 'job_type': 'TrainModel', 'loss': 0.6584872603416443, 'generations': 2, 'dataset_names': ['outbreak'], 'artifact_names': None, 'model_name': 'illnesses_model1', 'job_error': ''}\n",
      "{'status': 'Running', 'starttime': '2019-04-17T17:37:14.580578', 'endtime': None, 'percent_complete': 7, 'job_type': 'TrainModel', 'loss': 0.6584872603416443, 'generations': 2, 'dataset_names': ['outbreak'], 'artifact_names': None, 'model_name': 'illnesses_model1', 'job_error': ''}\n",
      "{'status': 'Running', 'starttime': '2019-04-17T17:37:14.580578', 'endtime': None, 'percent_complete': 7, 'job_type': 'TrainModel', 'loss': 0.6584872603416443, 'generations': 2, 'dataset_names': ['outbreak'], 'artifact_names': None, 'model_name': 'illnesses_model1', 'job_error': ''}\n",
      "{'status': 'Running', 'starttime': '2019-04-17T17:37:14.580578', 'endtime': None, 'percent_complete': 7, 'job_type': 'TrainModel', 'loss': 0.6584872603416443, 'generations': 2, 'dataset_names': ['outbreak'], 'artifact_names': None, 'model_name': 'illnesses_model1', 'job_error': ''}\n",
      "{'status': 'Running', 'starttime': '2019-04-17T17:37:14.580578', 'endtime': None, 'percent_complete': 7, 'job_type': 'TrainModel', 'loss': 0.6584872603416443, 'generations': 2, 'dataset_names': ['outbreak'], 'artifact_names': None, 'model_name': 'illnesses_model1', 'job_error': ''}\n",
      "{'status': 'Running', 'starttime': '2019-04-17T17:37:14.580578', 'endtime': None, 'percent_complete': 7, 'job_type': 'TrainModel', 'loss': 0.6584872603416443, 'generations': 2, 'dataset_names': ['outbreak'], 'artifact_names': None, 'model_name': 'illnesses_model1', 'job_error': ''}\n",
      "{'status': 'Running', 'starttime': '2019-04-17T17:37:14.580578', 'endtime': None, 'percent_complete': 7, 'job_type': 'TrainModel', 'loss': 0.6584872603416443, 'generations': 2, 'dataset_names': ['outbreak'], 'artifact_names': None, 'model_name': 'illnesses_model1', 'job_error': ''}\n",
      "{'status': 'Running', 'starttime': '2019-04-17T17:37:14.580578', 'endtime': None, 'percent_complete': 7, 'job_type': 'TrainModel', 'loss': 0.6584872603416443, 'generations': 2, 'dataset_names': ['outbreak'], 'artifact_names': None, 'model_name': 'illnesses_model1', 'job_error': ''}\n",
      "{'status': 'Complete', 'starttime': '2019-04-17T17:37:14.580578', 'endtime': '2019-04-17T17:39:21.04446', 'percent_complete': 100, 'job_type': 'TrainModel', 'loss': 0.6584872603416443, 'generations': 2, 'dataset_names': ['outbreak'], 'artifact_names': None, 'model_name': 'illnesses_model1', 'job_error': ''}\n"
     ]
    }
   ],
   "source": [
    "model = 'illnesses' + \"_model1\"\n",
    "status, job_id = ds.create_model(dataset_names = 'outbreak', \\\n",
    "                                 model_name =  model, \\\n",
    "                                 max_train_time = '00:02')\n",
    "if status:\n",
    "    ds.wait_for_job(job_id['job_name'])\n",
    "else:\n",
    "    print(job_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra Training (Optional)\n",
    "Run the following cell for extra training, no need to specify parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train some more\n",
    "status, job_id = ds.resume_training_model(dataset_names = dataset_name,\n",
    "                                          model_name = model,\n",
    "                                          max_train_time = '00:05')\n",
    "                                          \n",
    "if status:\n",
    "    ds.wait_for_job(job_id['job_name'])\n",
    "else:\n",
    "    print(job_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze Model\n",
    "Analyze model provides feature importance ranked by the model. <br> It indicates a general view of which features pose a bigger impact on the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'status': 'Running', 'starttime': '2019-04-17T17:40:28.7781', 'endtime': None, 'percent_complete': 0, 'job_type': 'AnalyzeModel', 'loss': 0.6584872603416443, 'generations': 2, 'dataset_names': None, 'artifact_names': ['12542baef8bf4a15b862cd415fb1dae1'], 'model_name': 'illnesses_model1', 'job_error': ''}\n",
      "{'status': 'Complete', 'starttime': '2019-04-17T17:40:28.7781', 'endtime': '2019-04-17T17:40:39.205932', 'percent_complete': 100, 'job_type': 'AnalyzeModel', 'loss': 0.6584872603416443, 'generations': 2, 'dataset_names': None, 'artifact_names': ['12542baef8bf4a15b862cd415fb1dae1'], 'model_name': 'illnesses_model1', 'job_error': ''}\n"
     ]
    }
   ],
   "source": [
    "# Retrieve feature importance of built model\n",
    "status, artifact = ds.analyze_model('illnesses_model1')\n",
    "sleep(1)\n",
    "if status:\n",
    "    ds.wait_for_job(artifact['job_name'])\n",
    "else:\n",
    "    print(artifact)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show the 10 most important features of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "hospitalizations                          0.232533\n",
       "year                                      0.178419\n",
       "illnesses                                 0.168933\n",
       "etiology_status = Suspected               0.148510\n",
       "etiology_status = Suspected; Suspected    0.083955\n",
       "etiology_status = Confirmed; Confirmed    0.062698\n",
       "month = 9                                 0.012465\n",
       "month = 7                                 0.009659\n",
       "month = 12                                0.009618\n",
       "etiology_status = Confirmed; Suspected    0.008575\n",
       "dtype: float64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importance[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions\n",
    "**Perform model prediction on the the training dataset.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "status, artifact = ds.run_model(dataset_name, model)\n",
    "sleep(1)\n",
    "ds.wait_for_job(artifact['job_name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download predictions from Darwin's server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "status, prediction = ds.download_artifact(artifact['artifact_name'])\n",
    "prediction.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create plots comparing predictions with actual target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "unq = prediction[target].unique()[::-1]\n",
    "p = np.zeros((len(prediction),))\n",
    "a = np.zeros((len(prediction),))\n",
    "for i,q in enumerate(unq):\n",
    "    p += i*(prediction[target] == q).values\n",
    "    a += i*(df[target] == q).values\n",
    "#Plot predictions vs actual\n",
    "plt.plot(a)\n",
    "plt.plot(p)\n",
    "plt.legend(['Actual','Predicted'])\n",
    "plt.yticks([i for i in range(len(unq))],[q for q in unq]);\n",
    "print(classification_report(df[target], prediction[target]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Perform model prediction on a test dataset that wasn't used in training.** <br>\n",
    "Upload test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_data = 'cancer_test.csv'\n",
    "status, dataset = ds.upload_dataset(os.path.join(path, test_data))\n",
    "if not status:\n",
    "    print(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "clean test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean test dataset\n",
    "status, job_id = ds.clean_data(test_data, target = target, model_name = model)\n",
    "\n",
    "if status:\n",
    "    ds.wait_for_job(job_id['job_name'])\n",
    "else:\n",
    "    print(job_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run model on test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "status, artifact = ds.run_model(test_data, model)\n",
    "sleep(1)\n",
    "ds.wait_for_job(artifact['job_name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create plots comparing predictions with actual target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create plots comparing predictions with actual target\n",
    "status, prediction = ds.download_artifact(artifact['artifact_name'])\n",
    "df = pd.read_csv(os.path.join(path,test_data))\n",
    "unq = prediction[target].unique()[::-1]\n",
    "p = np.zeros((len(prediction),))\n",
    "a = np.zeros((len(prediction),))\n",
    "for i,q in enumerate(unq):\n",
    "    p += i*(prediction[target] == q).values\n",
    "    a += i*(df[target] == q).values\n",
    "#Plot predictions vs actual\n",
    "plt.plot(a)\n",
    "plt.plot(p)\n",
    "plt.legend(['Actual','Predicted'])\n",
    "plt.yticks([i for i in range(len(unq))],[q for q in unq]);\n",
    "print(classification_report(df[target], prediction[target]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find out which machine learning model did Darwin use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'type': 'RandomForestRegressor', 'parameters': {'bootstrap': True, 'criterion': 'mse', 'max_depth': 3, 'max_features': 1.0, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_jobs': -1, 'n_estimators': 100}}\n"
     ]
    }
   ],
   "source": [
    "status, model_type = ds.lookup_model_name('illnesses_model1')\n",
    "print(model_type['description']['best_genome'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
